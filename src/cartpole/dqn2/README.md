# deep q-learning cartpole

## Overview
A deep q-learning approach to solving OpenAI Gym's Cartpole environment. We used a neural net of 3 layers--an input layer taking 4 inputs corresponding to observations from the environment (cart position, cart velocity, pole angle, pole velocity), a hidden layer with 24 nodes, and an output layer with 2 outputs corresponding to the potential actions.